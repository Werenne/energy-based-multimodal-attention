@ARTICLE{afouras,
       author = {{Afouras}, Triantafyllos and {Son Chung}, Joon and {Senior}, Andrew and
         {Vinyals}, Oriol and {Zisserman}, Andrew},
        title = "{Deep Audio-Visual Speech Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = "2018",
        month = "Sep",
          eid = {arXiv:1809.02108},
        pages = {arXiv:1809.02108},
archivePrefix = {arXiv},
       eprint = {1809.02108},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180902108A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{jaiswal,
       author = {{Jaiswal}, Ayush and {Sabir}, Ekraam and {AbdAlmageed}, Wael and
         {Natarajan}, Premkumar},
        title = "{Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Multimedia, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = "2017",
        month = "Jul",
          eid = {arXiv:1707.01606},
        pages = {arXiv:1707.01606},
archivePrefix = {arXiv},
       eprint = {1707.01606},
 primaryClass = {cs.MM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170701606J},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{dae-vincent,
       author = {{Vincentl}, Pascal and {Larochelle}, Hugo,  {Bengio}, Yoshua and and
         {Manzagol}, Pierre-Antoine},
        title = "{Extracting and Composing Robust Features with Denoising
Autoencoders}",
      journal = {ICML 2008},
     keywords = {Computer Science - Multimedia, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = "2008",
}

@ARTICLE{alainbengio,
       author = {{Alain}, Guillaume and {Bengio}, Yoshua},
        title = "{What Regularized Auto-Encoders Learn from the Data Generating Distribution}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2012",
        month = "Nov",
          eid = {arXiv:1211.4246},
        pages = {arXiv:1211.4246},
archivePrefix = {arXiv},
       eprint = {1211.4246},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2012arXiv1211.4246A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{potentialenergy,
       author = {{Kamyshanska}, Hanna  and {Memisevic}, Roland},
        title = "{The Potential Energy of an Autoencoder}",
      journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE (TPAMI)},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = "2014"
}

@ARTICLE{liu-kuan,
       author = {{Liu}, Kuan and {Li}, Yanen and {Xu}, Ning and {Natarajan}, Prem},
        title = "{Learn to Combine Modalities in Multimodal Deep Learning}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = "2018",
        month = "May",
          eid = {arXiv:1805.11730},
        pages = {arXiv:1805.11730},
archivePrefix = {arXiv},
       eprint = {1805.11730},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180511730L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{cocktail-party,
  author = {{Cocktail party effect}},
  title = "Cocktail party effect --- {W}ikipedia{,} The Free Encyclopedia",
  year = "2010",
  url = "https://en.wikipedia.org/wiki/Cocktail_party_effect",
  note = "[Online; accessed 29-April-2019]"
}

@ARTICLE{rbm,
       author = {{Montufar}, Guido},
        title = "{Restricted Boltzmann Machines: Introduction and Review}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Information Theory, Mathematics - Probability, Mathematics - Statistics Theory, Statistics - Machine Learning},
         year = "2018",
        month = "Jun",
          eid = {arXiv:1806.07066},
        pages = {arXiv:1806.07066},
archivePrefix = {arXiv},
       eprint = {1806.07066},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180607066M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{crossmodal,
title = "Crossmodal attention",
journal = "Current Opinion in Neurobiology",
volume = "8",
number = "2",
pages = "245 - 253",
year = "1998",
issn = "0959-4388",
doi = "https://doi.org/10.1016/S0959-4388(98)80147-5",
url = "http://www.sciencedirect.com/science/article/pii/S0959438898801475",
author = "Jon Driver and Charles Spence",
abstract = "Most selective attention research has considered only a single sensory modality at a time, but in the real world, our attention must be coordinated crossmodally. Recent studies reveal extensive crossmodal links in attention across the various modalities (i.e. audition, vision, touch and proprioception). Attention typically shifts to a common location across the modalities, despite the vast differences in their initial coding of space. These spatial synergies in attention can be maintained even when receptors are realigned across the modalities by changes in posture. Some crossmodal integration can arise preattentively. The mechanisms underlying these crossmodal links can be examined in a convergent manner by integrating behavioural studies of normal subjects and brain-damaged patients with neuroimaging and neurophysiological studies."
}

@ARTICLE{EBM,
       author = {{Osogami}, Takayuki},
        title = "{Boltzmann machines and energy-based models}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Neural and Evolutionary Computing},
         year = "2017",
        month = "Aug",
          eid = {arXiv:1708.06008},
        pages = {arXiv:1708.06008},
archivePrefix = {arXiv},
       eprint = {1708.06008},
 primaryClass = {cs.NE},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170806008O},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{ising-model,
  title = {The Spontaneous Magnetization of a Two-Dimensional Ising Model},
  author = {Yang, C. N.},
  journal = {Phys. Rev.},
  volume = {85},
  issue = {5},
  pages = {808--816},
  numpages = {0},
  year = {1952},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.85.808},
  url = {https://link.aps.org/doi/10.1103/PhysRev.85.808}
}

@ARTICLE{kahneman,
  
AUTHOR={Bruya, Brian and Tang, Yi-Yuan},   
	 
TITLE={Is Attention Really Effort? Revisiting Daniel Kahnemanâ€™s Influential 1973 Book Attention and Effort},      
	
JOURNAL={Frontiers in Psychology},      
	
VOLUME={9},      

PAGES={1133},     
	
YEAR={2018},      
	  
URL={https://www.frontiersin.org/article/10.3389/fpsyg.2018.01133},       
	
DOI={10.3389/fpsyg.2018.01133},      
	
ISSN={1664-1078},   
   
ABSTRACT={Daniel Kahneman was not the first to suggest that attention and effort are closely associated, but his 1973 book Attention and Effort, which claimed that attention can be identified with effort, cemented the association as a research paradigm in the cognitive sciences.  Since then, the paradigm has rarely been questioned and appears to have set the research agenda so that it is self-reinforcing.    In this article, we retrace Kahneman's argument to understand its strengths and weaknesses.  The central notion of effort is not clearly defined in the book, so we proceed by constructing the most secure inferences we can from Kahneman's argument regarding effort: it is cognitive, objective, metabolic expenditure, and it is attention.  Continuing, we find from Kahneman's argument that effort-attention must be a special case of sympathetic dominance of the autonomic nervous system that is also an increase in metabolic activity in the brain that has crossed a threshold of magnitude.  We then weigh this conception of effort against evidence in Kahneman's book and against more recent evidence, finding that it does not warrant the conclusion that effort can be equated with attention.  In support of an alternative perspective, we briefly review diverse studies of behavior, physiology and neuroscience on attention and effort, including meditation and studies of the LC-NE system, where we find evidence for the following: 1) Attention seems to be associated not with the utilization of metabolic resources per se but with the readying of metabolic resources in the form of adaptive gain modulation.  This occurs under sympathetic dominance and can be experienced as effortful.  2) Attention can also occur under parasympathetic dominance, in which case it is likely experienced as effortless.}
}







