\chapter{A Unified Model for Multi-Modal Attention} 
\label{chapter-unified} 

The purpose of using EMMA is to help the multi-modal network (MMN) to handle failing modes, and more generally, to figure out the relative emphases to be placed on the different modes depending on their general contributions to the predictions. The literature review\footnote{See Chapter \ref{chapter-literature-review}} discussed self-attention and cross-modal attention mechanisms, used to highlight information inside a specific mode, such as certain regions in an image or a set of frequencies in a sound. The difference between these two mechanisms is that self-attention only relies on information from the mode itself as a context, whereas cross-modal attention uses information from all the available modes. Now that we have EMMA, we claim to have all the ingredients to construct a complete multi-modal network like humans. As a reminder, human's complete multi-modal attention consists of three different components: exogenous, endogenous and cross-modal attention. The endogenous component of attention stems from a conscious, voluntary process, whereby a human elects to focus on a particular object \citep{crossmodal}. In contrast, the exogenous attention is triggered by the sudden onset of an unexpected event, and can thus be viewed as a reaction to an external stimulus \citep{crossmodal}. One way of constructing an endogenous module would be as a block of $M$ self-attentions, where each self-attention is dedicated to one specific mode. On the other hand, the attention module developed in this work can be interpreted as reproducing the exogenous attention used by humans to robustly handle abnormal situations.

\begin{figure}[hbt!]
\centering
\includegraphics[scale=0.75]{figures/unified}
\caption{A possible architecture for a unified multi-modal attention.}
\label{fig:complete-model}
\end{figure}

With this in mind, we present a unified model (see Figure \ref{fig:complete-model}) combining all the strengths of each type of attention. First, the attention masks $\beta_i$ computed by the exogenous model, and the attention masks $\mathbf{m}_i$ computed by the endogenous module, are combined to obtain the resulting masks $\beta_i\mathbf{m}_i$. These mask will highlight the most important modes, and on an intra-modal level attend to the most relevant regions. The masks $\beta_i\mathbf{m}_i$ are then applied to the input sample, which is passed through the cross-modal module. Finally, the processed input $\{\mathbf{x}''_1\,...\,\mathbf{x}''_M\}$ is forwarded to the MMN. In addition, the complete module can further be refined by inserting feedback loops from the previously predicted output to the separate modules, as it is often done in the literature \citep{afouras, attention-need, bahdanau}. For example, in a self-driving system, the attention module could improve its focus to different regions of the input image depending on the previously detected cars. It is worth mentioning that the proposed architecture is only a generalization of current attention modules such as in \citep{afouras}, supplemented with an exogenous component.


